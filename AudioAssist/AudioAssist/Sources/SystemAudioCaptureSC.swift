import Foundation
import AVFoundation
import ScreenCaptureKit
import CoreMedia

@available(macOS 13.0, *)
final class SystemAudioCaptureSC: NSObject, SCStreamOutput, SCStreamDelegate {

    // Dƒ±≈üarƒ±: 16 kHz, mono, Int16 PCM
    var onPCM16k: ((Data) -> Void)?

    private var stream: SCStream?
    private let audioQueue = DispatchQueue(label: "sc.audio.queue")
    private var converter: AVAudioConverter?

    // Hedef format: 48kHz, mono, Int16 interleaved (Deepgram ile uyumlu)
    private let outFmt = AVAudioFormat(
        commonFormat: .pcmFormatInt16,
        sampleRate: 48_000,
        channels: 1,
        interleaved: true
    )!

    // MARK: - Public
    
    /// Check screen recording permission and optionally request it
    func checkPermissions() async -> Bool {
        print("[SC] üîí Checking screen recording permission...")
        
        // Check current permission status
        let hasScreenPermission = CGPreflightScreenCaptureAccess()
        
        if hasScreenPermission {
            print("[SC] ‚úÖ Screen recording permission granted")
            return true
        } else {
            print("[SC] ‚ùå Screen recording permission denied")
            print("[SC] üîí Attempting to request permission...")
            
            // Try to request permission - this should make app appear in System Preferences
            let granted = CGRequestScreenCaptureAccess()
            print("[SC] üîí Permission request result: \(granted ? "‚úÖ Granted" : "‚ùå Still denied")")
            
            if !granted {
                print("[SC] üí° Please enable manually in System Preferences:")
                print("[SC] üí° Security & Privacy ‚Üí Privacy ‚Üí Screen Recording")
                print("[SC] üí° Find 'AudioAssist' in the list and check the box")
                print("[SC] üí° You may need to restart the app after granting permission")
            }
            
            return granted
        }
    }

    func start() async throws {
        print("[SC] üöÄ Starting SystemAudioCaptureSC...")
        
        // Check permissions first
        let hasPermission = await checkPermissions()
        guard hasPermission else {
            let error = NSError(domain: "SC", code: -2, 
                              userInfo: [NSLocalizedDescriptionKey: "Screen recording permission denied"])
            print("[SC] ‚ùå Permission denied: \(error.localizedDescription)")
            throw error
        }
        
        print("[SC] üöÄ requesting shareable content‚Ä¶")
        let content = try await SCShareableContent.current
        
        // üîç Debug: Mevcut i√ßeriƒüi logla
        print("[SC] üì∫ Available displays: \(content.displays.count)")
        for (index, display) in content.displays.enumerated() {
            print("[SC] üì∫ Display \(index): ID=\(display.displayID), Frame=\(display.frame)")
        }
        
        print("[SC] üì± Available applications: \(content.applications.count)")
        print("[SC] ü™ü Available windows: \(content.windows.count)")

        guard let display = content.displays.first else {
            print("[SC] ‚ùå No displays found!")
            throw NSError(domain: "SC", code: -1,
                          userInfo: [NSLocalizedDescriptionKey: "No displays found"])
        }

        print("[SC] üéØ Using display: ID=\(display.displayID)")

        // üëá Etiket sƒ±rasƒ±na dikkat: excludingApplications, exceptingWindows
        let filter = SCContentFilter(
            display: display,
            excludingApplications: [],
            exceptingWindows: []
        )

        let cfg = SCStreamConfiguration()
        cfg.capturesAudio = true        // ‚úÖ var
        // cfg.capturesVideo = false     // ‚ùå b√∂yle bir alan yok, ekleme
        cfg.sampleRate = 48_000
        cfg.channelCount = 2            // sistem miks genelde stereo
        
        // üîç Debug: Konfig√ºrasyonu detaylƒ± logla
        print("[SC] ‚öôÔ∏è Stream Configuration:")
        print("[SC] ‚öôÔ∏è   - capturesAudio: \(cfg.capturesAudio)")
        print("[SC] ‚öôÔ∏è   - sampleRate: \(cfg.sampleRate) Hz")
        print("[SC] ‚öôÔ∏è   - channelCount: \(cfg.channelCount) channels")
        print("[SC] ‚öôÔ∏è   - Output format: \(outFmt.sampleRate) Hz, \(outFmt.channelCount) ch, \(outFmt.commonFormat.rawValue)")

        print("[SC] üîß Creating SCStream...")
        let s = SCStream(filter: filter, configuration: cfg, delegate: self)
        
        print("[SC] üîß Adding stream output...")
        try s.addStreamOutput(self, type: .audio, sampleHandlerQueue: audioQueue)
        
        print("[SC] üîß Starting capture...")
        try await s.startCapture()
        self.stream = s

        print("[SC] ‚úÖ SystemAudioCaptureSC started successfully!")
    }

    func stop() async {
        try? await stream?.stopCapture()
        stream = nil
        converter = nil
        print("[SC] ‚èπÔ∏è stopped")
    }

    // MARK: - SCStreamOutput

    func stream(_ stream: SCStream,
                didOutputSampleBuffer sampleBuffer: CMSampleBuffer,
                of type: SCStreamOutputType) {

        guard type == .audio else { 
            print("[SC] ‚ö†Ô∏è Received non-audio type: \(type)")
            return 
        }
        
        guard CMSampleBufferDataIsReady(sampleBuffer) else { 
            print("[SC] ‚ö†Ô∏è Sample buffer data not ready")
            return 
        }

        // üîç Debug: Ses verisi detaylarƒ±
        let sampleCount = CMSampleBufferGetNumSamples(sampleBuffer)
        let duration = CMSampleBufferGetDuration(sampleBuffer)
        let durationSeconds = CMTimeGetSeconds(duration)
        let timestamp = CMSampleBufferGetPresentationTimeStamp(sampleBuffer)
        let timestampSeconds = CMTimeGetSeconds(timestamp)
        
        print("[SC] üéµ Audio received: \(sampleCount) samples, duration: \(String(format: "%.3f", durationSeconds))s, timestamp: \(String(format: "%.3f", timestampSeconds))s")

        // Giri≈ü formatƒ±nƒ± √ßƒ±kar
        guard let fd = CMSampleBufferGetFormatDescription(sampleBuffer),
              let asbdPtr = CMAudioFormatDescriptionGetStreamBasicDescription(fd) else { 
            print("[SC] ‚ùå Failed to get format description")
            return 
        }

        var asbd = asbdPtr.pointee
        guard let inFmt = AVAudioFormat(streamDescription: &asbd) else { 
            print("[SC] ‚ùå Failed to create input format")
            return 
        }

        // Converter yoksa/format deƒüi≈ütiyse olu≈ütur
        if converter == nil || converter?.inputFormat != inFmt {
            print("[SC] üîÑ Creating new converter...")
            print("[SC] üîÑ Input format: \(inFmt)")
            print("[SC] üîÑ Output format: \(outFmt)")
            
            converter = AVAudioConverter(from: inFmt, to: outFmt)
            if converter != nil {
                print("[SC] ‚úÖ Converter created successfully")
            } else {
                print("[SC] ‚ùå Failed to create converter")
                return
            }
        }
        guard let converter = converter else { return }

        // CMSampleBuffer -> AVAudioPCMBuffer
        guard let inBuf = sampleBuffer.makePCMBuffer(format: inFmt) else { return }

        // √áƒ±kƒ±≈ü buffer'ƒ±
        let outCap = AVAudioFrameCount(Double(inBuf.frameLength) * outFmt.sampleRate / inFmt.sampleRate)
        guard let outBuf = AVAudioPCMBuffer(pcmFormat: outFmt, frameCapacity: outCap) else { return }

        var err: NSError?
        _ = converter.convert(to: outBuf, error: &err) { _, outStatus in
            outStatus.pointee = .haveData
            return inBuf
        }
        if let err { print("[SC] ‚ùå convert error: \(err.localizedDescription)"); return }

        // Int16 veriyi Data'ya √ßevir
        guard let ch = outBuf.int16ChannelData?.pointee else { return }
        let byteCount = Int(outBuf.frameLength) * MemoryLayout<Int16>.size
        let data = Data(bytes: ch, count: byteCount)

        // üîä dƒ±≈üarƒ± yayƒ±nla
        onPCM16k?(data)
        print("[SC] üì§ Sent \(data.count) bytes to callback (48kHz mono Int16: \(data.count/2) samples)")
    }

    // MARK: - SCStreamDelegate

    // Optional @objc method ‚Äî uyarƒ± olmamasƒ± i√ßin @objc ≈üart
    @objc func stream(_ stream: SCStream, didStopWithError error: Error) {
        print("[SC] ‚ùå Stream stopped with error: \(error.localizedDescription)")
        print("[SC] üîç Error details: \(error)")
    }
}

// MARK: - Helpers

@available(macOS 13.0, *)
private extension CMSampleBuffer {
    /// CMSampleBuffer i√ßindeki ses verisini AVAudioPCMBuffer'a kopyalar
    func makePCMBuffer(format: AVAudioFormat) -> AVAudioPCMBuffer? {
        let frames = AVAudioFrameCount(CMSampleBufferGetNumSamples(self))
        guard let buf = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frames) else { return nil }
        buf.frameLength = frames

        var block: CMBlockBuffer?
        var abl = AudioBufferList(
            mNumberBuffers: 1,
            mBuffers: AudioBuffer(mNumberChannels: format.channelCount,
                                  mDataByteSize: 0,
                                  mData: nil)
        )

        let st = CMSampleBufferGetAudioBufferListWithRetainedBlockBuffer(
            self,
            bufferListSizeNeededOut: nil,
            bufferListOut: &abl,
            bufferListSize: MemoryLayout<AudioBufferList>.size,
            blockBufferAllocator: nil,
            blockBufferMemoryAllocator: nil,
            flags: 0,
            blockBufferOut: &block
        )
        if st != noErr { return nil }

        let src = abl.mBuffers

        // üîß AVAudioPCMBuffer'ƒ±n MUTABLE ABL'sini al
        let dstABLPtr = buf.mutableAudioBufferList
        
        // AudioBufferList'in mNumberBuffers kontrol√º
        if dstABLPtr.pointee.mNumberBuffers > 0 {
            // ƒ∞lk buffer'a eri≈üim
            dstABLPtr.pointee.mBuffers.mNumberChannels = src.mNumberChannels
            dstABLPtr.pointee.mBuffers.mDataByteSize = src.mDataByteSize

            if dstABLPtr.pointee.mBuffers.mData == nil {
                dstABLPtr.pointee.mBuffers.mData = malloc(Int(src.mDataByteSize))
            }
            if let dst = dstABLPtr.pointee.mBuffers.mData, let s = src.mData {
                memcpy(dst, s, Int(src.mDataByteSize))
            }
        }
        return buf
    }
}